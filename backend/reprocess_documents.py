#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ RAG
"""
import asyncio
import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é
sys.path.insert(0, str(Path(__file__).parent))

from app.core.database import AsyncSessionLocal
from app.services.rag_service import rag_service
from app.services.qwen_service import qwen_service
from app.core.storage import download_file
from app.services.document_processor import DocumentProcessor
from sqlalchemy import select
from app.models.document import Document
import tempfile
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def reprocess_documents():
    """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ RAG"""
    async with AsyncSessionLocal() as db:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        result = await db.execute(
            select(Document).where(Document.is_deleted == False)
        )
        docs = result.scalars().all()
        
        logger.info(f"üìÑ –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(docs)}")
        
        processor = DocumentProcessor()
        
        for doc in docs:
            logger.info(f"\n{'='*60}")
            logger.info(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {doc.title} (ID: {doc.id})")
            logger.info(f"{'='*60}")
            
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª –∏–∑ MinIO
                logger.info("üì• –ó–∞–≥—Ä—É–∂–∞—é —Ñ–∞–π–ª –∏–∑ MinIO...")
                file_data = download_file(doc.path)
                logger.info(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω, —Ä–∞–∑–º–µ—Ä: {len(file_data)} –±–∞–π—Ç")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
                file_ext = Path(doc.path).suffix
                with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp:
                    tmp.write(file_data)
                    tmp_path = tmp.name
                
                try:
                    logger.info("üìù –ò–∑–≤–ª–µ–∫–∞—é —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")
                    text = processor.load_file(tmp_path)
                    logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                    
                    if not text or len(text.strip()) < 10:
                        logger.warning(f"‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç {doc.title} —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞, –ø—Ä–æ–ø—É—Å–∫–∞—é")
                        continue
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ RAG –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
                    logger.info("üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —á–µ—Ä–µ–∑ RAG...")
                    metrics = await rag_service.process_document_for_metrics(
                        text=text,
                        filename=doc.title,
                        file_size=len(file_data)
                    )
                    logger.info(f"‚úÖ RAG –æ–±—Ä–∞–±–æ—Ç–∞–ª: {metrics.get('chunks_count', 0)} —á–∞–Ω–∫–æ–≤")
                    
                    # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç —á–µ—Ä–µ–∑ Qwen
                    logger.info("ü§ñ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É—é –¥–æ–∫—É–º–µ–Ω—Ç —á–µ—Ä–µ–∑ Qwen...")
                    classification = await qwen_service.classify_metrics_from_rag(
                        text=text[:2000],  # –ü–µ—Ä–≤—ã–µ 2000 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                        filename=doc.title,
                        metrics=metrics
                    )
                    logger.info(f"‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: —Ç–∏–ø={classification.get('type')}, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç={classification.get('priority')}")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏ —á–∞–Ω–∫–∏ –≤ Postgres
                    logger.info("üíæ –°–æ—Ö—Ä–∞–Ω—è—é —á–∞–Ω–∫–∏ –≤ Postgres...")
                    await rag_service.save_metrics_to_postgres(
                        db=db,
                        document_id=str(doc.id),
                        metrics=metrics,
                        classification_result=classification
                    )
                    await db.commit()
                    logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç {doc.title} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
                    
                finally:
                    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    try:
                        os.unlink(tmp_path)
                    except:
                        pass
                        
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc.title}: {e}")
                import traceback
                traceback.print_exc()
                await db.rollback()
                continue
        
        logger.info(f"\n{'='*60}")
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        logger.info(f"{'='*60}")

if __name__ == "__main__":
    asyncio.run(reprocess_documents())

